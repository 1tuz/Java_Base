#собеседования
### 1. Какая архитектура была на проекте/проектах?
- Микросервисная архитектура с использованием Docker и Kubernetes для контейнеризации и оркестрации.
### 2. Какой у тебя коммерческий опыт с Java? С какими версиями удалось поработать? 
- Коммерческий опыт с Java составляет 3.5 года. Работал с Java 11 и Java 17.
### 3. С какими java фреймворками ты работал? (если работал со Spring Data, Cloud и т.д. - укажи все)
- Spring Boot, Spring Data JPA, Spring Security, Spring Cloud, Kafka, Spring web, mvc
### 6. Какой у тебя опыт работы с Hibernate? (коммерческий в годах)
- Коммерческий опыт работы с Hibernate составляет 3.5 года.
### 7. Был ли опыт работы с Jenkins? (если да, так же укажи в годах)
- Да, опыт работы с Jenkins составляет 1.6 г в первой компании, всем занимался девопс, мне требовалось буквально нажимать билд и деплой. 
### 8. С какими форматами данных работал: JSON, XML? (если и с другими укажи их)
- JSON
### 9. С каким контейнером ты работал? (если несколько укажи все) 
- Docker. Также использовал Kubernetes для оркестрации контейнеров
### 10. Занимался ли ты написанием unit тестов? Что использовал? Какой процент покрытия?
- Да, использовал JUnit и Mockito. Процент покрытия составлял около 50%, включая юнит-тесты и интеграционные тесты.
### 11. Знаком ли с функцией peek? Встречался ли ты с ней в работе? 
- Да, знаком с функцией peek. Встречался в работе с Java Stream API для выполнения промежуточных операций без изменения потока данных. Нужно было отладить поток данных, который фильтровал и преобразовывал объекты заявок перед их сохранением в базу данных. В процессе отладки требовалось проверить, какие элементы проходят через каждый этап потока.
### 12. Работал с многопоточкой? Опиши подробнее чем занимался
- Нет, не работал.
- Да, работал с многопоточностью. Использовал ExecutorService для управления пулом потоков, Future и Callable для асинхронного выполнения задач, а также синхронизацию с помощью synchronized и Lock
### 13. Какая БД была на проекте? Как ты с ней взаимодействовал? (проектирование, моделирование, миграция)
- На проекте использовались PostgreSQL. Взаимодействовал через Hibernate и Spring Data JPA, занимался проектированием и моделированием схемы базы данных, а также миграцией данных.
### 14. Какой у тебя опыт с SQL? Написанием каких запросов ты занимался? (Можешь перечислить).
- Опыт с SQL включает написание запросов SELECT, INSERT, UPDATE, DELETE, JOIN, а также сложных запросов с использованием подзапросов, агрегатных функций и индексов.
### 15. Знаком ли тебе Бинарный поиск, в чем он заключается?
- Да, знаком. Бинарный поиск — это алгоритм поиска элемента в отсортированном массиве, который делит массив пополам и сравнивает средний элемент с искомым, что позволяет найти элемент за логарифмическое время.
### 16. Работал ли ты с терминальными конечными функциями Stream API? (опиши подробнее)
- Да, работал с терминальными конечными функциями Stream API, такими как forEach, collect, reduce, count, anyMatch, allMatch, noneMatch. Использовал их для выполнения различных операций над потоками данных, таких как сбор в коллекции, подсчет элементов, проверка условий и выполнение действий над каждым элементом.