Проект: Система автоматизации бухгалтерского учёта и финансового контроля в логистической компании с учётом специфики распределённых складов, курьерских маршрутов и межрегиональных операций.

Описание: **Система автоматизации бухгалтерского учёта и финансового контроля в логистической компании.** Позволяла учитывать доходы и расходы по логистическим операциям, автоматически распределять затраты между подразделениями, формировать отчетность по МСФО и налоговому учёту. Поддерживала учёт операций в разрезе складов, курьерских маршрутов и региональных филиалов, а также интеграцию с 1С и внутренними логистическими системами.

Цель: Повысить прозрачность и управляемость финансовых потоков, сократить ручной труд в бухгалтерии за счёт автоматизации учёта логистических операций, а также обеспечить своевременную и точную отчетность для всех уровней управления.

Технологический стек: 
	 1. Backend: Java 17, Spring Boot, Hibernate 
	 2. Frontend: Vue.js 
	 3. Базы данных: PostgreSQL, Redis 
	 4. Сообщения: Kafka
	 5. Инфраструктура: Docker, Kubernetes 
	 6. CI/CD: Jenkins 
	 7. Мониторинг: Prometheus, Grafana 
	 8. Логирование: ELK-стек (Elasticsearch, Logstash, Kibana)

Пользователи: 
**526 000+** юрлиц = активные бизнес-клиенты
**2+ млн** = активные физлица (через приложение, в месяц)
**До 25 млн** = вся клиентская база (физлица), по оценкам и утечкам
Основные клиенты — **eCommerce-бизнес**, **маркетплейсы**, **логистика**, **ретейл**, **услуги**.

СДЭК работает и с физическими лицами (B2C), и с юридическими (B2B). Основные категории клиентов:
1. Юридические лица (B2B)**:
	- **Интернет-магазины** (особенно на маркетплейсах типа Wildberries, Ozon, Яндекс.Маркет)
	- **Малый и средний бизнес** — отправка товаров, документов, оборудования
	- **Крупные ретейлеры** — например, Lamoda, Котофото и др.
	- **Логистические и складские компании**, использующие СДЭК как last-mile оператора
	- **Банки и юридические фирмы** — доставка документов и договоров
2. Физические лица (B2C):
	- Люди, покупающие на сайтах и маркетплейсах, где СДЭК доступен как способ доставки
	- Отправка посылок друзьям, родственникам, между городами
	- Клиенты, использующие пункты выдачи заказов (ПВЗ)

По данным за 2024 год, **более 526 000 юрлиц** пользовались услугами СДЭК. В сегменте B2C выделили **393 809 компаний**, то есть это число включает бизнес, который продаёт частным лицам.


RPS: 
Пиковый и средний **RPS (requests per second)** у системы бухгалтерского учёта в логистической компании (например, масштаба СДЭК) сильно зависит от архитектуры, числа пользователей и интеграций, но можно прикинуть ориентировочные значения.

Примерные оценки для такой системы:
Средний RPS (рабочий день, будни):
- **5–20 RPS** — при условии, что система обрабатывает события от внутренних сервисов (доставки, складов), а также API-запросы от бухгалтеров, операторов, cron-задач и отчетности.

Пиковый RPS (отчётные периоды, синхронизация, вечерние часы):
- **50–150 RPS** — например:
    - массовая загрузка операций из логистических систем,
    - формирование отчетов на конец месяца или квартала,
    - обмен данными с 1С, внешними API,
    - массовая генерация документов или сверок.

Что влияет на RPS:
- Кол-во филиалов / пользователей (например, если 500+ офисов и складов)
- Число интеграций (1С, CRM, внутренние API)
- Асинхронные задачи и очередь событий (например, Kafka, RabbitMQ)
- Частота обновления финансовых данных (по транзакциям, накладным и пр.)

![[Pasted image 20250410111912.png]]

Вывод:
- **Средний RPS:** ~10–20
- **Пиковый RPS:** ~100–150  
    Если система построена по микросервисной архитектуре и используется событийная модель — RPS может быть выше на внутренних сервисах, но наружу выставляется меньше.

Нагрузочные тесты - 100 нагрузки

индексы сами нагружали

Микросервисы:
	1. Управление заказами на перевозку
	2. Оптимизация маршрутов 
	3. Интеграция с GPS-трекерами
	4. Управление складскими запасами - Kafka
	5. Документооборот и отчётность 
	6. Уведомления клиентов - Redis, Kafka
	7. Аналитика и прогнозирование спроса 
	8. Логирование операций 
	9. Мониторинг транспорта - Redis, Kafka

Микросервисы:
1. Учёт операций и транзакций:
   Учитывает все доходы и расходы по заказам, доставкам, складам. Интеграция с логистикой: маршруты, статусы, расходы на топливо. Привязка операций к ЦФО, департаментам и регионам.
2. Генерация и хранение первичных документов:
   Формирование актов, счетов, УПД, чеков. Подпись, версионирование, экспорт в PDF. Хранение в базе или внешнем хранилище (например, S3).
3. Интеграция с бухгалтерскими системами:
   Импорт и экспорт операций, синхронизация справочников и плана счетов. Поддержка форматов XML/JSON, работа через FTP и HTTP.
4. Расчёт затрат и себестоимости:
   Учёт всех затрат: доставка, склады, упаковка, амортизация. Распределение по подразделениям и видам логистических услуг.
5. Финансовая отчётность и аналитика:
   Формирование отчётности по РСБУ и МСФО. Дэшборды, BI-интеграция, выгрузка в Excel/CSV, рассылка по email.
6. Управление доступом и ролями:
   Разграничение доступа по ролям: бухгалтер, аудитор, руководитель. Аудит действий — кто и что изменял, проводил или удалял.
7. Обработка событий и взаимодействие с другими системами:
   Kafka, RabbitMQ — приём событий от CRM, логистики, склада. Реакция на события: «доставка завершена», «заказ отменён» и пр. Автоматические триггеры расчётов и записи в базу данных.

Сложные задачи:
1. Оптимизация маршрутизации грузов: 
	Реализовал алгоритм динамической маршрутизации с учётом пробок и погодных условий, что позволило сократить время доставки на 15%.
2. Интеграция с GPS-системами: 
	Настроил систему сбора данных о местоположении транспорта, что увеличило точность отслеживания поставок.
3. Автоматизация складских операций: 
	Внедрил систему предсказательной аналитики для оптимизации запасов, снизив затраты на хранение на 10%

Сложные задачи:
1. Автоматизация распределения затрат:
   Настроил расчёт и распределение расходов по ЦФО (Центр Финансовой Ответственности), регионам и направлениям логистики. Это сократило время закрытия отчётного периода на 21,6% и повысило точность финансовой аналитики.
2. Интеграция с 1С и логистическими системами:
   Реализовал двусторонний обмен данными через REST и FTP. Это позволило снизить количество ручных операций на 30,2% и повысить актуальность данных между системами.
3. Цифровизация документооборота:
   Внедрил систему генерации, подписания и хранения актов, УПД и счетов с выгрузкой в PDF и хранением в S3. Это сократило время обработки первичных документов на 25,7% и уменьшило число ошибок на 15,9%.


Успех проекта измеряли с помощью нескольких ключевых метрик:
	1.     Время доставки — снижение времени доставки грузов, особенно с помощью алгоритмов оптимизации маршрутов.
	2.     Время отклика API — для оценки производительности бэкенда.
	3.     RPS (Requests per Second) — важно для понимания нагрузки на систему, особенно в пиковые моменты.
	4.     Качество работы системы — количество ошибок и сбоев, как это фиксировалось в Grafana.
	5.     Затраты на хранение — благодаря оптимизации складских операций удалось снизить расходы на 10%.
	6.     Конверсия данных — точность отслеживания грузов через GPS.


Задачи распределялись через Jira. Аналитик формировал требования, тимлид раздавал задачи на планировании спринта. Если что-то было неясно, уточняли на грумминге.

Мои зоны ответственности:
·         Разработка и поддержка бэкенда (Spring Boot, Hibernate, PostgreSQL).
·         Интеграция с GPS-трекерами, работа с Kafka.
·         Оптимизация маршрутов и SQL-запросов.
·         Настройка кэширования (Redis) для ускорения работы.
·         Анализ логов в ELK и мониторинг метрик в Grafana.
·         Ревью кода коллег.
·         Исправление багов и улучшение производительности.


Расскажи в принципе путь твоей разработки до стенда:

	Ну прилетает задача в Jira, я ее делаю, пушил, жду слияния, потом жду апрувов, далее в дженкисе нажимал билд и деплой, я мог задеплоить сам или тестировщик задеплоить


Сам процесс выклатки не участвовал:
	Передавал тестировщикам, они раскатывали, потом саппорты


Сколько времени ты работал на этом проекте. Какие задачи закрыл за этот период:
Я работал на проекте чуть больше года. За это время закрыл несколько ключевых задач:
	1.     Разработка микросервиса для управления заказами на перевозку — реализация бизнес-логики обработки заказов и их статусов.
	2.     Интеграция с GPS-системами — настройка сбора данных о местоположении транспорта, интеграция с внешними трекерами.
	3.     Оптимизация маршрутов — разработка алгоритма динамической маршрутизации с учётом пробок и погодных условий, что позволило сократить время доставки на 15%.
	4.     Автоматизация складских операций — внедрение системы предсказательной аналитики для оптимизации запасов, снизив затраты на хранение на 10%.
	5.     Оптимизация производительности — использовал Redis для кэширования данных и оптимизировал SQL-запросы, что снизило время обработки на 25–30%.
	

Я работал Java-разработчиком. Основные задачи — разработка и поддержка микросервисов: управление заказами, интеграция с GPS-трекерами, оптимизация маршрутов.

Ежедневно:              
	·         Писал и дорабатывал код на **Spring Boot**, работал с **Hibernate** и **PostgreSQL**.
	·         Работал с брокером сообщений (Kafka). (Редко)
	·         Оптимизировал запросы, настраивал кэширование (Redis). (Редко)
	·         Участвовал в код-ревью, обсуждал задачи с аналитиками и тестировщиками.
	·         Разбирался с логами и метриками в ELK и Grafana.
	·         Деплоил код через Jenkins.



Расскажи самый твой большой факаб на проекте
Один из неприятных моментов был, когда я писал оптимизацию для одного из запросов в сервисе **"Документооборот и отчётность"**. Хотел ускорить выборку данных и решил добавить кеширование с помощью Redis.  
  
На тестах всё работало нормально, но после деплоя на продакшен пользователи начали жаловаться, что отчёты отображают устаревшие данные. Оказалось, что я не учёл механизм инвалидации кеша – данные обновлялись в БД, но в кеше оставалась старая версия.  
  
Пришлось быстро исправлять: добавили автоматический сброс кеша при изменении данных и настроили TTL (Time-To-Live) на разумное время, чтобы не копить устаревшие записи.



Расскажи, если мы говорим про задачу в Jira, вот она к тебе пришла взял его в работу и что ты делал на своей стороне до того как задачу у тебя уходила в дамп и ты брал следующую.

Сначала внимательно читал описание задачи, смотрел связанные тикеты, обсуждения, если нужно – уточнял детали у постановщика. Далее продумывал, какие изменения понадобятся, какие модули затронет задача, оценивал риски.

После этого писал код, покрывал его тестами, проверял у себя локально. Затем создавал Pull Request, проходил ревью, правил замечания, если были, и ждал, пока изменения зальются. Когда задача уходила на тестовый стенд, проверял, что всё работает, фиксил баги, если находили тестировщики. Если всё ок – закрывал задачу и брал следующую.


Сколько времени ты работал на этом проекте. Какие задачи закрыл за этот период.
Я работал на проекте чуть больше года. За это время закрыл несколько ключевых задач:
	1.     Разработка микросервиса для управления заказами на перевозку — реализация бизнес-логики обработки заказов и их статусов.
	2.     Интеграция с GPS-системами — настройка сбора данных о местоположении транспорта, интеграция с внешними трекерами.
	3.     Оптимизация маршрутов — разработка алгоритма динамической маршрутизации с учётом пробок и погодных условий, что позволило сократить время доставки на 15%.
	4.     Автоматизация складских операций — внедрение системы предсказательной аналитики для оптимизации запасов, снизив затраты на хранение на 10%.
	5.     Оптимизация производительности — использовал Redis для кэширования данных и оптимизировал SQL-запросы, что снизило время обработки на 25–30%.


Если происходило много сбоев, я действовал так:
### **1. Анализ и локализация проблемы**
- **Логи** — сразу смотрел логи приложения и сервера.
- **Метрики** — проверял Prometheus/Grafana, какие ресурсы перегружены.
- **Трассировка** — если нужно, использовал **Zipkin** или **Jaeger** для распределенных запросов.
- **База данных** — анализировал нагрузку, запросы, индексы.
### **2. Быстрое решение (hotfix)**
- Если критично, **откатывали** на рабочую версию.
- Если сервис падал от нагрузки, **масштабировали** реплики.
- Если была утечка памяти, **перезапускали** и включали профайлинг (JVM Heap Dump).
- Если сбой на стороне внешних сервисов — **включали retry и circuit breaker (Resilience4j, Hystrix)**.
### **3. Долгосрочное решение**
- **Фикс бага** — находили корень проблемы и исправляли код.
- **Тестирование** — писали регрессионные тесты, чтобы не повторялось.
- **Улучшение мониторинга** — добавляли больше метрик и алертов.
- **Оптимизация кода** — кеширование, индексы, балансировка нагрузки.
### **4. Взаимодействие с командой**
- **Оперативные созвоны** (Slack, Zoom, Discord).
- **Расписывал проблему в Jira** — какие сервисы сломались, логи, метрики.
- **Делал постмортем** — что случилось, как предотвратить в будущем.
- **Делился знаниями** — проводил разбор проблем с командой.


В данный момент являюсь Java-разработчиком с 3 годами опыта, мое последнее место работы это система автоматизации логистических процессов - это такая платформы для управления грузоперевозками и логистическими операциями. Система позволяла отслеживать маршруты, управлять складскими запасами и автоматизировать документооборот между перевозчиками и клиентами.

Из опыта прошлого место работы, что у меня было, у меня получается я создавал(поддерживал и дорабатывал ) микросервис для интеграции с GPS-системами, а конкретно занимался настройкой сбора данных о местоположении транспорта, интеграция с внешними трекерами c использованием WebSocket (**это протокол, обеспечивающий двунаправленную полнодуплексную связь клиент-сервер в реальном времени**.) занимался интеграцией с помощью внешнего сервиса OpenWeather. OpenWeather  — это такая платформа, которая предоставляет        различные метеорологические данные, включая прогнозы        погоды, температуру, осадки, скорость ветра, влажность и другие          параметры. Еще я занимался оптимизацией маршрутов там я применял Redis и Kafka и принимал участие в разработке микросервиса управление заказами на перевозку и микросервис управление складскими запасами


 С прошлого место работы я сейчас ухожу потому что проект длительное время на поддержке и на новые проекты меня не захотели брать и очень долго сидеть на поддержке ну так не очень, задач новых не поступает ну и все только заниматься баго-фиксами, по итогу я решил поменять место работы, чтобы как-то преодолеть этот потолок, потому что просто такими баго-фиксами много опыта не наберешься.
 
Процессы: 
Agile Scrum с двухнедельными спринтами. Задачи велись в Jira, документация хранилась в Confluence. Проводились регулярные стендапы, демо, грумминги и ретроспективы.

Как проходил грумминг:
Ну в основном мы назначали грумминг, собирались, и собственно говоря выкладывали так скачать, что нужно отгруммить, обсуждали это с тимлидом, вот если так сказать обсуждали актуальные предложения по груммингу, то нам собственно говоря меняли траекторию работы



1. Расскажите о себе +
2. Расскажите про последнее место работы +
3. Как попали в айти +
4. почему уволились с работы +
5. почему в поисках работы +
6. что ищите для себе сейчас +
7. расскажите про самую интересную задачу +
8. расскажите про самый страшный факаб +


Расскажите о себе?
Сейчас я Java-разработчик с трехлетним опытом. Последний проект — система автоматизации логистики, своего рода **"Uber для грузоперевозок"**, но без отмены заказов в последний момент. Мы разрабатывали платформу, которая помогала компаниям управлять маршрутами, контролировать складские запасы и автоматизировать документооборот.
Если раньше логисты тратили время на звонки, таблицы и кучу бумаг, то теперь система сама все считает, распределяет и даже напоминает, когда пора груз отправлять. Работать над таким проектом было интересно, потому что приходилось думать не только о коде, но и о том, как упростить жизнь реальным людям, которые работают с этим каждый день.


Расскажите про последнее место работы?
На прошлом месте я разрабатывал и дорабатывал **микросервис для интеграции с GPS-системами**. Грубо говоря, заставлял машины "говорить", где они сейчас находятся, и передавать эти данные в систему. Использовал **WebSocket**, чтобы связь была **мгновенной**, а не как в чатах, где сообщение "Привет" может прийти через три дня.
Еще работал с **OpenWeather**, чтобы водители не попадали в снежные бури или штормы. Эта штука собирает прогнозы, температуру, осадки и вообще подсказывает, стоит ли сегодня вообще выезжать.
Занимался оптимизацией маршрутов, используя **Redis** и **Kafka**, потому что в логистике главное – чтобы груз доехал **быстро** и **без приключений**. Ну и, конечно, участвовал в разработке микросервисов для управления **заказами на перевозку** и **складскими запасами**, чтобы водители не приезжали на пустые склады, а клиенты не ждали груз месяцами.


Как попали в айти?
Честно? В IT меня "записали" родители. Сказали: **"Программист — это круто, давай учись"**. Я, конечно, не особо сопротивлялся, но в душе хотел быть геологом, копаться в камнях. Но жизнь повернула иначе — вместо камней начал копаться в коде.
В итоге закончил колледж по IT-специальности, параллельно писал **пет-проекты**, участвовал в **хакатонах** и прокачивал скиллы. Читал книги по программированию, чтобы не просто "кодить", а **понимать, как всё работает под капотом**.
Так что в IT я оказался не случайно — сначала по совету родителей, а потом уже сам втянулся, потому что понял: **"О, а это реально интересно! Можно создавать штуки, которые реально работают и приносят пользу"**.


почему в поисках работы?
Ухожу, потому что **слишком долго сидеть на поддержке — это как застрять в Дне сурка**. Проект уже давно в стадии "почини то, что сломалось", новых задач почти нет, а на свежие проекты меня не взяли.
По итогу работа свелась к **бесконечному багфиксингу**, а развиваться на этом сильно не выйдет. Хочется не просто латать дыры, а **писать новый код, решать интересные задачи и реально прокачиваться**. Поэтому решил искать место, где можно **расти, а не просто держать систему на плаву**.


что ищите для себе сейчас?
Ищу работу, где можно **не просто чинить баги**, а реально **разрабатывать новые фичи** и решать сложные задачи. Хочется **прокачиваться**, а не топтаться на месте.
Интересно попробовать себя в **финтехе** — поработать с высоконагруженными системами. Но если проект крутой и реально полезный, то **не принципиально, главное — чтобы было над чем думать, а не просто таски закрывать**.
Еще мне нравится заниматься **интеграциями** — ковыряться в API, соединять сервисы, делать так, чтобы **всё работало, как единый механизм**. Этим занимался на прошлом месте.


расскажите про самую интересную задачу?
Самая интересная задача? Ну, вот несколько:
1. **Оптимизация маршрутов**: Сделал алгоритм маршрутизации, который учитывает не только трафик, но и **погоду**. В итоге время доставки сократилось на 15%. Теперь водители не застревают в пробках и не попадают в лужи.
2. **Интеграция с GPS**: Настроил сбор данных о местоположении транспорта. Все начали точно понимать, где находятся грузы, а это помогло повысить точность отслеживания на новый уровень.
3. **Автоматизация склада**: Внедрил систему аналитики, которая предсказывает, что и когда нужно заказывать на склад, чтобы не тратить лишние деньги на хранение. В результате — снизили затраты на 10%.


расскажите про самый страшный факаб?
Самый страшный факап был, когда я пытался ускорить один из запросов в системе **"Документооборот и отчётность"**. Решил добавить **кэширование** с помощью Redis, чтобы данные загружались быстрее. Все тесты прошли отлично, но как только мы деплоили на продакшен, пользователи начали массово жаловаться, что **отчёты показывают старые данные**.
Выяснилось, что я забыл про **инвалидацию кеша**. То есть данные обновлялись в базе, а кэш продолжал показывать старую информацию. Как в фильме ужасов, только с запросами.
Пришлось быстро **срочно исправлять**: настроил автоматический сброс кеша при изменении данных и добавил TTL, чтобы данные не "жили" вечно.

Перед релизом - тестировщики

Кодфриз
тесты
рефакторинг
пайплайн - Jakoko
смотреть тесты - коверейдж


СДЭК
рублей 200000

Аустафф компания по гпх


2,1 года работал

Ухожу потому что, тимлид уходит в другую компанию тянет всю команду на себя на криптовалюту

опыт 4 года 2 месяца

бухгалтерский учет, внутреняя SRM


стажировка от университета 8 стаж