Проект: Система автоматизации бухгалтерского учёта и финансового контроля в логистической компании с учётом специфики распределённых складов, курьерских маршрутов и межрегиональных операций.

Описание: **Система автоматизации бухгалтерского учёта и финансового контроля в логистической компании.** Позволяла учитывать доходы и расходы по логистическим операциям, автоматически распределять затраты между подразделениями, формировать отчетность по МСФО и налоговому учёту. Поддерживала учёт операций в разрезе складов, курьерских маршрутов и региональных филиалов, а также интеграцию с 1С и внутренними логистическими системами.

Цель: Повысить прозрачность и управляемость финансовых потоков, сократить ручной труд в бухгалтерии за счёт автоматизации учёта логистических операций, а также обеспечить своевременную и точную отчетность для всех уровней управления.

Технологический стек: 
	 1. Backend: Java 17, Spring Boot, Hibernate 
	 2. Frontend: Vue.js 
	 3. Базы данных: PostgreSQL, Redis 
	 4. Сообщения: Kafka
	 5. Инфраструктура: Docker, Kubernetes 
	 6. CI/CD: Jenkins 
	 7. Мониторинг: Prometheus, Grafana 
	 8. Логирование: ELK-стек (Elasticsearch, Logstash, Kibana)

Пользователи: 
**526 000+** юрлиц = активные бизнес-клиенты
**2+ млн** = активные физлица (через приложение, в месяц)
**До 25 млн** = вся клиентская база (физлица), по оценкам и утечкам
Основные клиенты — **eCommerce-бизнес**, **маркетплейсы**, **логистика**, **ретейл**, **услуги**.

СДЭК работает и с физическими лицами (B2C), и с юридическими (B2B). Основные категории клиентов:
1. Юридические лица (B2B)**:
	- **Интернет-магазины** (особенно на маркетплейсах типа Wildberries, Ozon, Яндекс.Маркет)
	- **Малый и средний бизнес** — отправка товаров, документов, оборудования
	- **Крупные ретейлеры** — например, Lamoda, Котофото и др.
	- **Логистические и складские компании**, использующие СДЭК как last-mile оператора
	- **Банки и юридические фирмы** — доставка документов и договоров
2. Физические лица (B2C):
	- Люди, покупающие на сайтах и маркетплейсах, где СДЭК доступен как способ доставки
	- Отправка посылок друзьям, родственникам, между городами
	- Клиенты, использующие пункты выдачи заказов (ПВЗ)

По данным за 2024 год, **более 526 000 юрлиц** пользовались услугами СДЭК. В сегменте B2C выделили **393 809 компаний**, то есть это число включает бизнес, который продаёт частным лицам.


RPS: 
Пиковый и средний **RPS (requests per second)** у системы бухгалтерского учёта в логистической компании (например, масштаба СДЭК) сильно зависит от архитектуры, числа пользователей и интеграций, но можно прикинуть ориентировочные значения.

Примерные оценки для такой системы:
Средний RPS (рабочий день, будни):
- **5–20 RPS** — при условии, что система обрабатывает события от внутренних сервисов (доставки, складов), а также API-запросы от бухгалтеров, операторов, cron-задач и отчетности.

Пиковый RPS (отчётные периоды, синхронизация, вечерние часы):
- **50–150 RPS** — например:
    - массовая загрузка операций из логистических систем,
    - формирование отчетов на конец месяца или квартала,
    - обмен данными с 1С, внешними API,
    - массовая генерация документов или сверок.

Что влияет на RPS:
- Кол-во филиалов / пользователей (например, если 500+ офисов и складов)
- Число интеграций (1С, CRM, внутренние API)
- Асинхронные задачи и очередь событий (например, Kafka, RabbitMQ)
- Частота обновления финансовых данных (по транзакциям, накладным и пр.)

![[Pasted image 20250410111912.png]]

Вывод:
- **Средний RPS:** ~10–20
- **Пиковый RPS:** ~100–150  
    Если система построена по микросервисной архитектуре и используется событийная модель — RPS может быть выше на внутренних сервисах, но наружу выставляется меньше.

Нагрузочные тесты - 100 нагрузки

индексы сами нагружали


Микросервисы:
1. Учёт операций и транзакций: 
   Учитывает все доходы и расходы по заказам, доставкам, складам. Интеграция с логистикой: маршруты, статусы, расходы на топливо. Привязка операций к ЦФО, департаментам и регионам.
	- **Kafka** может использоваться для асинхронной обработки событий, связанных с учётом операций, например, обновление записей в случае новых транзакций или изменений в статусах заказов.
	- **Redis** может быть использован для кэширования промежуточных данных, таких как статусы доставки, что ускоряет доступ к часто используемым данным.
2. Генерация и хранение первичных документов:
   Формирование актов, счетов, УПД, чеков. Подпись, версионирование, экспорт в PDF. Хранение в базе или внешнем хранилище (например, S3).
3. Интеграция с бухгалтерскими системами:
   Импорт и экспорт операций, синхронизация справочников и плана счетов. Поддержка форматов XML/JSON, работа через FTP и HTTP.
4. Расчёт затрат и себестоимости:
   Учёт всех затрат: доставка, склады, упаковка, амортизация. Распределение по подразделениям и видам логистических услуг.
5. Финансовая отчётность и аналитика:
   Формирование отчётности по РСБУ и МСФО. Дэшборды, BI-интеграция, выгрузка в Excel/CSV, рассылка по email.
	- **Kafka** может использоваться для обработки и передачи событий, таких как создание/обновление финансовых отчетов, которые требуют агрегации данных из нескольких источников.
	- **Redis** может использоваться для хранения временных данных или промежуточных результатов аналитики, таких как часто запрашиваемые отчёты, для быстрого доступа и минимизации времени ожидания.
6. Управление доступом и ролями:
   Разграничение доступа по ролям: бухгалтер, аудитор, руководитель. Аудит действий — кто и что изменял, проводил или удалял.
	   **Redis** может использоваться для хранения информации о сессиях и авторизации пользователей с высокой скоростью, что помогает уменьшить нагрузку на основной источник данных.
7. Обработка событий и взаимодействие с другими системами: 
   Kafka — приём событий от CRM, логистики, склада. Реакция на события: «доставка завершена», «заказ отменён» и пр. Автоматические триггеры расчётов и записи в базу данных.
	- **Kafka** может использоваться для асинхронной обработки событий, связанных с учётом операций, например, обновление записей в случае новых транзакций или изменений в статусах заказов.
	- **Redis** может быть использован для кэширования промежуточных данных, таких как статусы доставки, что ускоряет доступ к часто используемым данным.


Сложные задачи:
1. Автоматизация распределения затрат:
   Настроил расчёт и распределение расходов по ЦФО (Центр Финансовой Ответственности), регионам и направлениям логистики. Это сократило время закрытия отчётного периода на 21,6% и повысило точность финансовой аналитики.
2. Интеграция с 1С и логистическими системами:
   Реализовал двусторонний обмен данными через REST и FTP. Это позволило снизить количество ручных операций на 30,2% и повысить актуальность данных между системами.
3. Цифровизация документооборота:
   Внедрил систему генерации, подписания и хранения актов, УПД и счетов с выгрузкой в PDF и хранением в S3. Это сократило время обработки первичных документов на 25,7% и уменьшило число ошибок на 15,9%.


ЦФО - Это организационная единица в компании (например, отдел, филиал или подразделение), которая отвечает за свои доходы и расходы. В крупных компаниях, особенно в логистике, таких центров может быть много — по регионам, складам, направлениям бизнеса и т.д.
Каждому ЦФО ставятся финансовые цели, и потом анализируется эффективность: прибыль, рентабельность, выполнение бюджета и т.п.
Компания вроде СДЭК делит свою структуру на **ЦФО** по регионам: Москва, Санкт-Петербург, Екатеринбург и т.д.
Допустим, **московский филиал** — это отдельный ЦФО. Он:
- получает выручку от доставки в пределах Москвы и исходящих отправлений,
- несёт расходы на курьеров, аренду склада, топливо, обработку заказов,
- отвечает за прибыльность филиала.
Таким образом, можно посчитать:  
Доходы филиала — Расходы филиала = Финансовый результат ЦФО.

Такой подход помогает руководству понять, какие регионы работают эффективно, а где нужно оптимизировать расходы или пересмотреть бизнес-процессы.


Успех проекта измеряли с помощью нескольких ключевых метрик:
	1.     Время доставки — снижение времени доставки грузов, особенно с помощью алгоритмов оптимизации маршрутов.
	2.     Время отклика API — для оценки производительности бэкенда.
	3.     RPS (Requests per Second) — важно для понимания нагрузки на систему, особенно в пиковые моменты.
	4.     Качество работы системы — количество ошибок и сбоев, как это фиксировалось в Grafana.
	5.     Затраты на хранение — благодаря оптимизации складских операций удалось снизить расходы на 10%.
	6.     Конверсия данных — точность отслеживания грузов через GPS.


Задачи распределялись через Jira. Аналитик формировал требования, тимлид раздавал задачи на планировании спринта. Если что-то было неясно, уточняли на грумминге.

Мои зоны ответственности:
·         Разработка и поддержка бэкенда (Spring Boot, Hibernate, PostgreSQL).
·         Интеграция с GPS-трекерами, работа с Kafka.
·         Оптимизация маршрутов и SQL-запросов.
·         Настройка кэширования (Redis) для ускорения работы.
·         Анализ логов в ELK и мониторинг метрик в Grafana.
·         Ревью кода коллег.
·         Исправление багов и улучшение производительности.


Расскажи в принципе путь твоей разработки до стенда:

	Ну прилетает задача в Jira, я ее делаю, пушил, жду слияния, потом жду апрувов, далее в дженкисе нажимал билд и деплой, я мог задеплоить сам или тестировщик задеплоить


Сам процесс выклатки не участвовал:
	Передавал тестировщикам, они раскатывали, потом саппорты


Сколько времени ты работал на этом проекте. Какие задачи закрыл за этот период:
Я работал на проекте чуть больше двух года. За это время закрыл несколько ключевых задач:
	1.     **Учёт операций и транзакций**:  
			Реализовал учёт всех доходов и расходов по заказам, доставкам и складам, интегрировав систему с логистическими сервисами для получения данных о маршрутах, статусах и расходах на топливо. Все операции были привязаны к ЦФО и регионам.
	2.     **Генерация и хранение первичных документов**:  
			Разработал механизм автоматического формирования актов, счетов, УПД и чеков, с поддержкой подписи, версионирования и экспорта в PDF. Все документы хранились в базе данных или облачном хранилище (например, S3).
	3.     **Интеграция с бухгалтерскими системами**:  
			Отвечал за интеграцию с бухгалтерскими системами для импорта и экспорта операций, синхронизацию планов счетов и справочников. Реализовал поддержку форматов XML/JSON и работу через FTP/HTTP
	4.     **Расчёт затрат и себестоимости**:  
			Разработал систему для учёта всех затрат, связанных с доставкой, складами, упаковкой и амортизацией, а также для распределения этих затрат по подразделениям и видам логистических услуг.
	5.     Оптимизация производительности — использовал Redis для кэширования данных и оптимизировал SQL-запросы, что снизило время обработки на 25–30%.
	

Я работал Java-разработчиком. Основные задачи — разработка и поддержка микросервисов: управление заказами, интеграция с GPS-трекерами, оптимизация маршрутов.

Ежедневно:              
	·         Писал и дорабатывал код на **Spring Boot**, работал с **Hibernate** и **PostgreSQL**.
	·         Работал с брокером сообщений (Kafka). (Редко)
	·         Оптимизировал запросы, настраивал кэширование (Redis). (Редко)
	·         Участвовал в код-ревью, обсуждал задачи с аналитиками и тестировщиками.
	·         Разбирался с логами и метриками в ELK и Grafana.
	·         Деплоил код через Jenkins.


Расскажи, если мы говорим про задачу в Jira, вот она к тебе пришла взял его в работу и что ты делал на своей стороне до того как задачу у тебя уходила в дамп и ты брал следующую.

Сначала внимательно читал описание задачи, смотрел связанные тикеты, обсуждения, если нужно – уточнял детали у постановщика. Далее продумывал, какие изменения понадобятся, какие модули затронет задача, оценивал риски.

После этого писал код, покрывал его тестами, проверял у себя локально. Затем создавал Pull Request, проходил ревью, правил замечания, если были, и ждал, пока изменения зальются. Когда задача уходила на тестовый стенд, проверял, что всё работает, фиксил баги, если находили тестировщики. Если всё ок – закрывал задачу и брал следующую.


Если происходило много сбоев, я действовал так:
### **1. Анализ и локализация проблемы**
- **Логи** — сразу смотрел логи приложения и сервера.
- **Метрики** — проверял Prometheus/Grafana, какие ресурсы перегружены.
- **Трассировка** — если нужно, использовал **Zipkin** или **Jaeger** для распределенных запросов.
- **База данных** — анализировал нагрузку, запросы, индексы.
### **2. Быстрое решение (hotfix)**
- Если критично, **откатывали** на рабочую версию.
- Если сервис падал от нагрузки, **масштабировали** реплики.
- Если была утечка памяти, **перезапускали** и включали профайлинг (JVM Heap Dump).
- Если сбой на стороне внешних сервисов — **включали retry и circuit breaker (Resilience4j, Hystrix)**.
### **3. Долгосрочное решение**
- **Фикс бага** — находили корень проблемы и исправляли код.
- **Тестирование** — писали регрессионные тесты, чтобы не повторялось.
- **Улучшение мониторинга** — добавляли больше метрик и алертов.
- **Оптимизация кода** — кеширование, индексы, балансировка нагрузки.
### **4. Взаимодействие с командой**
- **Оперативные созвоны** (Slack, Zoom, Discord).
- **Расписывал проблему в Jira** — какие сервисы сломались, логи, метрики.
- **Делал постмортем** — что случилось, как предотвратить в будущем.
- **Делился знаниями** — проводил разбор проблем с командой.


 С прошлого место работы я сейчас ухожу потому что проект длительное время на поддержке и на новые проекты меня не захотели брать и очень долго сидеть на поддержке ну так не очень, задач новых не поступает ну и все только заниматься баго-фиксами, по итогу я решил поменять место работы, чтобы как-то преодолеть этот потолок, потому что просто такими баго-фиксами много опыта не наберешься.
 
Процессы: 
Agile Scrum с двухнедельными спринтами. Задачи велись в Jira, документация хранилась в Confluence. Проводились регулярные стендапы, демо, грумминги и ретроспективы.

Как проходил грумминг:
Ну в основном мы назначали грумминг, собирались, и собственно говоря выкладывали так скачать, что нужно отгруммить, обсуждали это с тимлидом, вот если так сказать обсуждали актуальные предложения по груммингу, то нам собственно говоря меняли траекторию работы



1. Расскажите о себе +
2. Расскажите про последнее место работы +
3. Как попали в айти +
4. почему уволились с работы +
5. почему в поисках работы +
6. что ищите для себе сейчас +
7. расскажите про самую интересную задачу +
8. расскажите про самый страшный факаб +


Расскажите о себе?
Сейчас я Java-разработчик с четырех летним опытом и занимаюсь проектом, который можно было бы назвать чем-то вроде **"Тотальный бухгалтер в мире логистики"**. Проект — автоматизировать бухгалтерский учёт и финансовый контроль в логистической компании. Учитывая, что складов много, маршруты курьеров меняются, а операции идут по всей стране, процесс автоматизации — не из простых. Мы сделали так, чтобы все расходы, доходы, расчёты себестоимости и отчётность автоматизировались с учётом этих нюансов.

Скажем так, если раньше бухгалтеры бегали с кучей бумажек и пытались вручную свести концы с концами, то теперь всё работает как по маслу, и вся эта бухгалтерия сама подсказывает, что и когда нужно делать. Для меня этот проект был отличным вызовом, ведь тут важно не только знать, как кодить, но и понимать, как сделать жизнь людей проще, которые работают с этим каждый день.

Онбординг

Сейчас я работаю Java-разработчиком, у меня около четырёх лет коммерческого опыта. Последние 2 года с копейкой я участвую в разработке внутренней системы автоматизации бухгалтерского учёта и финансового контроля для крупной логистической компании.

Проект охватывает широкий спектр задач, связанных с учётом финансов в условиях распределённой логистической инфраструктуры: множество складов, филиалов, направлений доставки, ЦФО и постоянные изменения маршрутов.

**ЦФО** (Центр Финансовой Ответственности) — это такие отдельные "ячейки" внутри компании, например, отделы или филиалы, которые сами отвечают за свои доходы и расходы. В крупных компаниях, как например в логистике, их может быть много — по регионам, складам или даже направлениям бизнеса. Каждому ЦФО ставятся финансовые цели, и потом смотрят, как оно работает: прибыль, рентабельность, выполнение бюджета и т.д. В компании типа СДЭК, например, делят на ЦФО по городам — Москва, Питер, Екатеринбург и так далее.
Допустим, **московский филиал** — это отдельный ЦФО. Он:
- получает выручку от доставки в пределах Москвы и исходящих отправлений,
- несёт расходы на курьеров, аренду склада, топливо, обработку заказов,
- отвечает за прибыльность филиала.
Таким образом, можно посчитать:  
Доходы филиала — Расходы филиала = Финансовый результат ЦФО.

Моя основная зона ответственности — бэкенд-часть. В рамках проекта я:

- **Разрабатывал микросервисы** для учёта доходов, расходов и транзакций по заказам, складам и регионам. Эти данные используются для формирования отчётности и расчёта себестоимости.
- **Реализовал систему генерации документов** (счета, акты, УПД, чеки) с последующим экспортом в PDF и сохранением в БД или в облаке.
- **Интегрировал систему с внешними API бухгалтерских платформ** (в том числе через XML/JSON по HTTP и FTP), чтобы обеспечивать актуальность данных и синхронизацию с бухгалтерскими системами.
- **Настроил расчёт затрат** по логистическим операциям: доставка, упаковка, складирование, амортизация. Эти данные используются для расчёта точной себестоимости и рентабельности.
- **Оптимизировал производительность** сервисов — реализовал кэширование с помощью Redis и использовал Kafka для асинхронной обработки данных, что позволило снизить нагрузку на систему при пиковых операциях и ускорить время ответа.
- **Реализовал расчёт и распределение расходов по ЦФО**, что помогло сократить время закрытия финансового периода более чем на 20%.

Работали по Scrum: участие в груммингах, дейликах, ретроспективах. Задачи велись в Jira, документация — в Confluence, код — в Git по Git Flow. Архитектура микросервисная, взаимодействие между сервисами через REST и очереди Kafka.



Расскажите про последнее место работы?
На прошлом месте я работал над **системой автоматизации бухгалтерии** для логистики. Например, я интегрировал систему с **внешними API** для синхронизации данных с бухгалтерией, чтобы все отчёты всегда были актуальны, и **WebSocket** использовал для получения данных в реальном времени – чтобы отчёты не приходили как из музея, а сразу, как только появились данные.


Вот что я делал:
1. **Учёт операций и транзакций**: Разработал систему для учёта доходов и расходов по заказам, складам и доставкам, интегрировав её с внешними логистическими сервисами через API. Использовал WebSocket для получения в реальном времени данных о маршрутах, статусах и расходах на топливо.
2. **Генерация документов**: Автоматизировал создание актов, счетов, УПД и чеков, экспортируя их в PDF. Все документы хранятся либо в базе данных, либо в облаке, чтобы ни одна бумажка не потерялась.
3. **Интеграция с бухгалтерией**: Настроил обмен данными с внешними бухгалтерскими системами через API, поддерживая форматы XML и JSON. Всё синхронизировалось через FTP и HTTP, чтобы не было никаких провалов.
4. **Расчёт затрат**: Построил систему для учёта всех затрат: доставка, склады, упаковка и амортизация. Всё это помогает точно рассчитывать себестоимость и помогает логистам не попадать в «минус».
5. **Оптимизация производительности**: Использовал Redis для кэширования данных и улучшил SQL-запросы, что уменьшило время обработки на 25-30%. Умная система, не правда ли?

В общем, работал с множеством интеграций, включая внешние API, а использование WebSocket в некоторых микросервисах позволило нам работать с данными в реальном времени. В целом, проект был интересным, потому что приходилось работать с кучей разных систем, а задача была не просто автоматизировать процесс, но и сделать его удобным для людей.


Вот с какими интеграциями я работал на проекте:
1. **Интеграция с логистическими сервисами**:  
    Мы подключали внешние API для получения данных о маршрутах, статусах доставок и расходах на топливо. Это позволило автоматически обновлять данные о движении грузов, а также учитывать топливные расходы в расчётах по каждому заказу.
2. **Интеграция с бухгалтерскими системами**:  
    Реализовали двусторонний обмен данными с различными бухгалтерскими системами, включая импорт и экспорт операций, синхронизацию планов счетов и справочников. Использовали форматы XML/JSON, обмен происходил через FTP и HTTP.
3. **Облачные хранилища (например, S3)**:  
    Для хранения генерируемых первичных документов использовалось облачное хранилище, где все актовые, счёт-фактурные и другие документы сохранялись для дальнейшего доступа и выгрузки. Это позволило масштабировать систему и обеспечить её доступность для всех заинтересованных сторон.
4. **Системы мониторинга и аналитики (BI)**:  
    Для формирования отчётности и аналитики интегрировали платформу с BI-инструментами, что позволило автоматически выгружать данные для дальнейшего анализа в Excel/CSV и представлять их в виде дэшбордов. Это упростило процесс формирования финансовых отчётов по РСБУ и МСФО.
5. **Интеграция с внутренними сервисами компании**:  
    Разработали механизмы интеграции с различными внутренними сервисами компании (например, складской системой и CRM), чтобы данные о заказах и доставках поступали из разных источников и синхронизировались в реальном времени.


Как попали в айти?
Честно? В IT меня "записали" родители. Сказали: **"Программист — это круто, давай учись"**. Я, конечно, не особо сопротивлялся, но в душе хотел быть геологом, копаться в камнях. Но жизнь повернула иначе — вместо камней начал копаться в коде.
В итоге закончил колледж по IT-специальности, параллельно писал **пет-проекты**, участвовал в **хакатонах** и прокачивал скиллы. Читал книги по программированию, чтобы не просто "кодить", а **понимать, как всё работает под капотом**.
Так что в IT я оказался не случайно — сначала по совету родителей, а потом уже сам втянулся, потому что понял: **"О, а это реально интересно! Можно создавать штуки, которые реально работают и приносят пользу"**.


почему в поисках работы?
Сейчас ищу новые предложения, потому что на старом месте стало нестабильно из-за сокращений. Некоторые коллеги уже ушли, и хоть меня пока не тронули, не хочу сидеть на вулкане. Хочется найти место, где есть уверенность в будущем, работать над интересными проектами и расти. Главное, чтобы была стабильность и возможность развиваться, а не просто поддерживать текущие процессы.


что ищите для себе сейчас?
Ищу работу, где можно **не просто чинить баги**, а реально **разрабатывать новые фичи** и решать сложные задачи. Хочется **прокачиваться**, а не топтаться на месте.
Интересно попробовать себя в **финтехе** — поработать с высоконагруженными системами. Но если проект крутой и реально полезный, то **не принципиально, главное — чтобы было над чем думать, а не просто таски закрывать**.
Еще мне нравится заниматься **интеграциями** — ковыряться в API, соединять сервисы, делать так, чтобы **всё работало, как единый механизм**. Этим занимался на прошлом месте.
	А почему вас не переводят на новые проекты в СДЭКЕ?
		В компании сейчас нет открытых новых продуктовых направлений, куда можно было бы перейти внутри. Я уже общался с руководством и уточнял, есть ли возможность внутреннего перевода, но на данный момент таких возможностей просто нет.


расскажите про самую интересную задачу?
Сложные задачи:
1. Автоматизация распределения затрат:
   Настроил расчёт и распределение расходов по ЦФО (Центр Финансовой Ответственности), регионам и направлениям логистики. Это сократило время закрытия отчётного периода на 21,6% и повысило точность финансовой аналитики.
2. Интеграция с 1С и логистическими системами:
   Реализовал двусторонний обмен данными через REST и FTP. Это позволило снизить количество ручных операций на 30,2% и повысить актуальность данных между системами.
3. Цифровизация документооборота:
   Внедрил систему генерации, подписания и хранения актов, УПД и счетов с выгрузкой в PDF и хранением в S3. Это сократило время обработки первичных документов на 25,7% и уменьшило число ошибок на 15,9%.

Сложность была в том, что данные расходов приходили из разных источников: склады, доставки, упаковка, зарплаты, топливо и т.п. И всё это нужно было правильно разложить по регионам, ЦФО и направлениям бизнеса.
У всех — разная логика учёта: где-то напрямую, где-то через коэффициенты (например, как делить расходы на топливо между заказами в одном регионе). При этом некоторые расходы "общие" — их надо было распределять по формуле, а не просто делить поровну.
Плюс, данные часто приходили с задержкой или в кривом виде, так что пришлось заморочиться с предобработкой, валидацией и кэшированием. Добавил Redis, оптимизировал SQL-запросы, и расчёты, которые раньше могли идти полчаса, стали выполняться за 3-4 минуты. Ну и отчётность теперь закрывается быстрее, без ручных правок в Excel.

**ЦФО** — это такие отдельные "ячейки" внутри компании, например, отделы или филиалы, которые сами отвечают за свои доходы и расходы. В крупных компаниях, как например в логистике, их может быть много — по регионам, складам или даже направлениям бизнеса. Каждому ЦФО ставятся финансовые цели, и потом смотрят, как оно работает: прибыль, рентабельность, выполнение бюджета и т.д. В компании типа СДЭК, например, делят на ЦФО по городам — Москва, Питер, Екатеринбург и так далее.
Допустим, **московский филиал** — это отдельный ЦФО. Он:
- получает выручку от доставки в пределах Москвы и исходящих отправлений,
- несёт расходы на курьеров, аренду склада, топливо, обработку заказов,
- отвечает за прибыльность филиала.
Таким образом, можно посчитать:  
Доходы филиала — Расходы филиала = Финансовый результат ЦФО.

Такой подход помогает руководству понять, какие регионы работают эффективно, а где нужно оптимизировать расходы или пересмотреть бизнес-процессы.

**УПД** — это такой документ, который часто используется для оформления сделок между компаниями. Он как бы сочетает в себе несколько документов: акт выполненных работ и счет-фактуру. Проще говоря, если ты передаёшь товар или оказываешь услугу, УПД подтверждает, что всё сделано, и ещё помогает с расчетами между сторонами. Всё это важно для учёта в налоговых органах. К тому же УПД часто оформляется в электронном виде, что гораздо удобнее и быстрее.


расскажите про самый страшный факаб?
**Самый страшный факап** случился, когда я решил «немного упростить жизнь бухгалтерам» и написал скрипт для автоматической отправки отчётности на e-mail. Всё шло по плану, пока утром один из руководителей филиала не получил **85 писем подряд** с одними и теми же отчётами.
Оказалось, я забыл поставить флажок, что отчёт уже отправлен. Скрипт бодро пробегал по каждому документу и радостно слал его снова и снова, пока не закончил список… и не начал сначала.
Бухгалтеры не оценили моё рвение к автоматизации. Пришлось в срочном порядке добавлять проверку статуса отправки и, как ни странно, учиться просить прощения у людей, которые следят за зарплатой.
После этого инцидента мы с тимлидом и командой сели и разобрали ситуацию по шагам. Решили, что:
1. **Любая автоматизация, связанная с внешними действиями (email, API и т.д.), должна иметь флаг "выполнено"** и журнал логирования, чтобы можно было отследить, что уже сделано.
2. Перед запуском в прод мы договорились всегда делать **dry run в тестовой среде**, особенно если изменения затрагивают массовые действия.
3. Добавили **ограничения на количество отправок в единицу времени**, чтобы если вдруг что-то пошло не так — можно было быстро заметить и остановить процесс.
4. Ну и внедрили **code review чек-лист**, куда включили пункт про проверку идемпотентности и наличие логов.
С тех пор подход к автоматизации стал гораздо аккуратнее — ошибок меньше, нервы целее.

А как вы обсуждали с тимлидом, в грумминге или на дейликах, либо в другом?
Мы обсудили это сначала **на дейлике**, когда я сразу рассказал о проблеме — решил не скрывать, чтобы быстро найти решение. Тимлид предложил вынести это на **грумминг**, где мы уже всей командой детально разобрали кейс, причины и как подобного избежать.
После обсуждения внесли изменения в наш процесс разработки: обновили **чек-листы на ревью**, добавили **тест-кейсы на отправку** и договорились, что любые такие потенциально массовые действия — только после dry-run на тестовой среде.


В основном на каких микросервисах стоят redis и kafka и по какому принципу они стоят и почему?
- **Redis** — когда нужно **мгновенно читать или временно хранить** данные.
- **Kafka** — когда нужно **передавать события между микросервисами** или **строить асинхронную архитектуру**.


Как происходил процесс деплоя в продакшен?

Через CI/CD — git push в main ветку запускал pipeline (например, GitLab CI), который собирал образ, пушил в registry и выкатывал через Docker/Kubernetes на прод. Всё автоматизировано.

стойрипоинт

Перед релизом - тестировщики

Кодфриз
тесты
рефакторинг
пайплайн - Jakoko
смотреть тесты - коверейдж


СДЭК
рублей 200000

Аустафф компания по гпх


2,1 года работал

Ухожу потому что, тимлид уходит в другую компанию тянет всю команду на себя на криптовалюту

опыт 4 года 2 месяца

бухгалтерский учет, внутреняя SRM


стажировка от университета 8 стаж