В **ELK (Elasticsearch, Logstash, Kibana)** анализ логов проводили    следующим образом:

Как собирали логи?
	·        **Logstash** парсил логи из файлов и контейнеров.
	·        **Filebeat** отправлял логи в **Elasticsearch**.
	·        **Elasticsearch** хранил и индексировал логи.
	·        **Kibana** визуализировала и фильтровала логи.

Какие фильтры применяли?
1. По уровню логов**: `INFO`, `WARN`, `ERROR`, `DEBUG`
	Например, искали только ошибки: level:ERROR
2. По сервису:
	Например, логика только микросервиса GPS-трекинга: service:gps-tracker
3. По **времени**:
	Фильтровали логи за последние 30 минут, час, день.
4. По traceId / requestId (трассировка запросов между микросервисами)
5. **По тексту в сообщении**:
       Искали специфические ошибки:
       message: "Timeout while calling external API"

Как искали баги:
	·        Проверяли **резкие скачки ошибок** (ERROR / WARN).
	·        Искали **таймауты и ретраи**.
	·        Сравнивали **разные версии приложения** (до и после релиза).
	·        Отслеживали **аномалии в логах** (например, увеличение нагрузки).

Плюс использовали APM (Elastic APM, Zipkin) для трассировки        запросов и поиска проблем в микросервисах.