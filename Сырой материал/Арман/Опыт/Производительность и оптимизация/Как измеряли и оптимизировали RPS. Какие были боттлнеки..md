**Как** **измеряли** **RPS (Requests Per Second)?**
	1.     **Метрики в Prometheus + Grafana** – снимали данные по http_requests_total, http_request_duration_seconds.
	2.     **Apache Benchmark (ab), wrk, k6, JMeter** – эмулировали нагрузку и замеряли пропускную способность API.
	3.     **Spring Actuator (/metrics)** – смотрели http.server.requests.
	4.     **Nginx / HAProxy / Traefik** – логировали RPS на уровне балансировщика.

**Как оптимизировали RPS?**
	1.     **Кэширование (Redis, Caffeine)** – уменьшали количество запросов в базу данных.
	2.     **Использование индексов в БД** – заменяли Seq Scan на Index Scan, пересматривали индексы.
	3.     **Асинхронная обработка (Kafka, CompletableFuture)** – тяжелые операции (например, обработка данных с GPS-трекеров) выносили в фоновые процессы.
	4.     **Балансировка нагрузки (Nginx, Kubernetes HPA)** – горизонтальное масштабирование микросервисов.
	5.     **Пула потоков в Spring Boot (ExecutorService)** – ограничивали количество активных потоков, чтобы избежать перегрузки CPU и БД.
	6.     **Batch-обработка** – вместо обработки каждой записи отдельно группировали данные и уменьшали число запросов.

**Основные боттлнеки**
	1.     **База данных** – высокая нагрузка на PostgreSQL (долгие запросы, блокировки, отсутствие индексов).
	2.     **Сетевые задержки** – медленные запросы к сторонним API (решали ретраями, Circuit Breaker).
	3.     **GC-паузы в JVM** – долгое время сборки мусора при высоких нагрузках.
	4.     **Ограничения по памяти / CPU** – контейнеры могли не справляться при росте нагрузки (настраивали limits в Kubernetes).
	5.     **Kafka lag** – если продюсеров было больше, чем потребителей, происходило отставание в обработке сообщений.