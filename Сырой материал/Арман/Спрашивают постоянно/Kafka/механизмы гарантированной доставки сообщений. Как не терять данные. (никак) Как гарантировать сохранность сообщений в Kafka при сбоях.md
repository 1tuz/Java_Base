В Kafka используются следующие механизмы минимизации потери данных:
1. Параметр `acks`: **`acks`** — это настройка, которая определяет, сколько подтверждений от сервера Kafka (брокера) нужно дождаться, чтобы считать сообщение успешно отправленным.
   Значения для `acks`:
	   1) **`0`**: Producer не ждет подтверждения от сервера. **Быстро**, но **сообщения могут потеряться** при сбоях.
	   2) **`1`**: Producer ждет подтверждение от одного брокера. Это минимальная гарантия доставки.
	   3) **`all`** или **`-1`**: Producer ждет подтверждения от всех брокеров (максимум гарантий доставки, но медленнее). 
2. Хранение сообщений на диске:
	1) Kafka сохраняет сообщения на диске, а не только в оперативной памяти.
	2) Это позволяет минимизировать потерю данных даже в случае сбоя сервера.
	3) При падении сервера все сообщения, сохраненные на диске, можно восстановить при перезапуске.
3. Репликация данных:
	1) **Репликация** означает, что каждое сообщение хранится на нескольких брокерах.
	   **Пример:** Сообщение записывается в партицию, и данные реплицируются на другие брокеры. Если один брокер сломается, данные можно получить с других.
4. Consumer с подтверждением (Commit): Когда Consumer получает сообщение, он может подтвердить, что обработал это сообщение (commit).
   Kafka поддерживает два типа подтверждений:
	   1) **Автоматическое подтверждение**: Consumer сообщает Kafka, что все успешно обработано.
	   2) **Ручное подтверждение**: Consumer сам контролирует, когда подтвердить сообщение.
	Если Consumer упадет до подтверждения, Kafka сможет повторно отправить это сообщение.

Почему невозможно полностью исключить потерю данных?
В распределенных системах и при работе с большими объемами данных всегда есть вероятность сбоя сети, ошибок сервера или других проблем.
Например:
1. Сервер может сломаться до того, как сообщение будет записано на диск.
2. Сбой сети может помешать отправке данных.
Поэтому **"никогда не терять данные на 100%"** невозможно, но можно минимизировать вероятность их потери с помощью следующих стратегий.